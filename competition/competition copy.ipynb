{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Here is the jupyter notebook for those who have signed up for the [competition](https://codalab.lisn.upsaclay.fr/competitions/8440?secret_key=51d5952f-d68d-47d9-baef-6032445dea01) in NTU.\n",
    "\n",
    "## Goal\n",
    "The competition's goal is to maximize the accumulative return rate of the test input. Based on the current price information, your agent should generate a portfolio weight which will give the hightest return rate defined below. \n",
    "\n",
    "## Dataset\n",
    "In this competition, you will be given 1 complete datasets as training dataset and 2 incomplete datasets as test datasets, where there is no feature `close`.\n",
    "\n",
    "In both complete and incomplete datasets, there are 15 assets.\n",
    "### Data Visualization\n",
    "Here is a glance of how the train data look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>tic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.008320</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>-0.010062</td>\n",
       "      <td>-0.143726</td>\n",
       "      <td>0.005374</td>\n",
       "      <td>-0.010348</td>\n",
       "      <td>-0.011415</td>\n",
       "      <td>0.002751</td>\n",
       "      <td>-0.061124</td>\n",
       "      <td>-0.072128</td>\n",
       "      <td>-0.126481</td>\n",
       "      <td>0</td>\n",
       "      <td>14.765714</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.005803</td>\n",
       "      <td>-0.005646</td>\n",
       "      <td>-0.225326</td>\n",
       "      <td>-0.005459</td>\n",
       "      <td>0.007794</td>\n",
       "      <td>-0.008521</td>\n",
       "      <td>-0.008222</td>\n",
       "      <td>-0.017393</td>\n",
       "      <td>-0.031253</td>\n",
       "      <td>-0.042012</td>\n",
       "      <td>0</td>\n",
       "      <td>63.759998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.004561</td>\n",
       "      <td>0.002902</td>\n",
       "      <td>-0.017413</td>\n",
       "      <td>-0.136140</td>\n",
       "      <td>-0.003100</td>\n",
       "      <td>0.004561</td>\n",
       "      <td>-0.004885</td>\n",
       "      <td>-0.017185</td>\n",
       "      <td>-0.029824</td>\n",
       "      <td>-0.045096</td>\n",
       "      <td>-0.052918</td>\n",
       "      <td>0</td>\n",
       "      <td>48.240002</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.003094</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>-0.009956</td>\n",
       "      <td>-0.181742</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.002922</td>\n",
       "      <td>-0.007421</td>\n",
       "      <td>-0.004776</td>\n",
       "      <td>-0.002812</td>\n",
       "      <td>-0.013054</td>\n",
       "      <td>-0.001687</td>\n",
       "      <td>0</td>\n",
       "      <td>74.330002</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.015182</td>\n",
       "      <td>0.006958</td>\n",
       "      <td>-0.015182</td>\n",
       "      <td>-0.252029</td>\n",
       "      <td>0.009257</td>\n",
       "      <td>0.010322</td>\n",
       "      <td>-0.004803</td>\n",
       "      <td>-0.010627</td>\n",
       "      <td>-0.001714</td>\n",
       "      <td>-0.005438</td>\n",
       "      <td>0.006133</td>\n",
       "      <td>0</td>\n",
       "      <td>94.849998</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0  -0.008320   0.002999  -0.010062  -0.143726   0.005374  -0.010348   \n",
       "0   0.005332   0.005803  -0.005646  -0.225326  -0.005459   0.007794   \n",
       "0  -0.004561   0.002902  -0.017413  -0.136140  -0.003100   0.004561   \n",
       "0  -0.003094   0.003632  -0.009956  -0.181742   0.001482   0.002922   \n",
       "0  -0.015182   0.006958  -0.015182  -0.252029   0.009257   0.010322   \n",
       "\n",
       "   feature_6  feature_7  feature_8  feature_9  feature_10  date      close  \\\n",
       "0  -0.011415   0.002751  -0.061124  -0.072128   -0.126481     0  14.765714   \n",
       "0  -0.008521  -0.008222  -0.017393  -0.031253   -0.042012     0  63.759998   \n",
       "0  -0.004885  -0.017185  -0.029824  -0.045096   -0.052918     0  48.240002   \n",
       "0  -0.007421  -0.004776  -0.002812  -0.013054   -0.001687     0  74.330002   \n",
       "0  -0.004803  -0.010627  -0.001714  -0.005438    0.006133     0  94.849998   \n",
       "\n",
       "   tic  \n",
       "0    0  \n",
       "0    1  \n",
       "0    2  \n",
       "0    3  \n",
       "0    4  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "train=pd.read_csv(\"data/train.csv\",index_col=0)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the RL setting, we view all 15 stocks's feature information as state, which is the input of your model.\n",
    "\n",
    "Here is a glance of what the state in timestamp 0 looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# technical_indicator_list=[\"feature_0\",\"feature_1\",\"feature_2\",\"feature_3\",\"feature_4\",\"feature_5\",\"feature_6\",\"feature_7\",\"feature_8\",\"feature_9\",\"feature_10\"]\n",
    "# train.loc[0][technical_indicator_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reward Calculation\n",
    "Based on the state in timestamp 0, we use random portfolio weights to demonstrate how the reward of the random action is calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003390615329232534"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate random action\n",
    "random_score=np.random.rand(15)\n",
    "random_weights=np.exp(random_score)/np.sum(np.exp(random_score))\n",
    "# calculate return_rate for every single ticker of day 0\n",
    "close_price_0=train.loc[0].close.values\n",
    "close_price_1=train.loc[1].close.values\n",
    "single_return_rate=close_price_1/close_price_0-1\n",
    "# calculate the return rate of the random action\n",
    "return_rate_action=np.sum(random_weights*single_return_rate)\n",
    "return_rate_action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide a [Trading Environment](https://github.com/TradeMaster-NTU/TradeMaster/blob/main/env/PM/portfolio_for_EIIE.py) to automate the process of state stepping and reward calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Implementation\n",
    "Here, we provide a baseline for the competition using one of the algorithms in TradeMaster. You can follow the rest jupyter notebook to create a borderline submission.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation\n",
    "\n",
    "Here we provide the [video tutorial](https://www.youtube.com/watch?v=7rtqFT9I4uo&t=12s) for you to install this project to better participate in the competition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL enviornment & baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Environment Set Up\n",
    "First, we need to add the project to our system path because the setting of jupter notebook is a little different from that of py document.\n",
    "Then, we need to load the document we need to import the module we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from agent.EIIE.model import EIIE_con, EIIE_lstm, EIIE_rnn, EIIE_critirc\n",
    "import argparse\n",
    "from agent.EIIE.util import *\n",
    "from env.PM.portfolio_for_EIIE import Tradingenv\n",
    "from logging import raiseExceptions\n",
    "from stat import S_ENFMT\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import sys\n",
    "from agent.EIIE.trader import trader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config and Hyperparameters Adjustment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a part where you can adjust the default hyperparameters\n",
    "More specifically, besides the hyperparameters the DPG need, it also contains information like the path of the config file of the training and validing environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--num_epoch'], dest='num_epoch', nargs=None, const=None, default=1, type=<class 'int'>, choices=None, help='the number of epoch we train', metavar=None)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--random_seed\",\n",
    "                    type=int,\n",
    "                    default=12345,\n",
    "                    help=\"random seed number\")\n",
    "parser.add_argument(\n",
    "    \"--env_config_path\",\n",
    "    type=str,\n",
    "    default=\"config/input_config/env/portfolio/portfolio_for_EIIE/\",\n",
    "    help=\"the path for storing the downloaded data\")\n",
    "parser.add_argument(\n",
    "    \"--net_type\",\n",
    "    choices=[\"conv\", \"lstm\", \"rnn\"],\n",
    "    default=\"rnn\",\n",
    "    help=\"the name of the model\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--num_hidden_nodes\",\n",
    "    type=int,\n",
    "    default=32,\n",
    "    help=\"the number of hidden nodes in lstm or rnn\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--num_out_channel\",\n",
    "    type=int,\n",
    "    default=2,\n",
    "    help=\"the number of channel\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--gamma\",\n",
    "    type=float,\n",
    "    default=0.99,\n",
    "    help=\"the gamma for DPG\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--model_path\",\n",
    "    type=str,\n",
    "    default=\"result/EIIE/trained_model\",\n",
    "    help=\"the path for trained model\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--result_path\",\n",
    "    type=str,\n",
    "    default=\"result/EIIE/test_result\",\n",
    "    help=\"the path for test result\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--num_epoch\",\n",
    "    type=int,\n",
    "    default=1,\n",
    "    help=\"the number of epoch we train\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Building & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "axes don't match array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\zzyy\\Desktop\\TradeMaster\\competition\\competition copy.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zzyy/Desktop/TradeMaster/competition/competition%20copy.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m args \u001b[39m=\u001b[39m parser\u001b[39m.\u001b[39mparse_args(args\u001b[39m=\u001b[39m[])\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/zzyy/Desktop/TradeMaster/competition/competition%20copy.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m agent\u001b[39m=\u001b[39mtrader(args)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zzyy/Desktop/TradeMaster/competition/competition%20copy.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# agent.train_with_valid()\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zzyy/Desktop/TradeMaster/competition/competition%20copy.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(agent\u001b[39m.\u001b[39mtrain_env_config)\n",
      "File \u001b[1;32mc:\\Users\\zzyy\\Desktop\\TradeMaster\\competition\\..\\agent\\EIIE\\trader.py:82\u001b[0m, in \u001b[0;36mtrader.__init__\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalid_env_config \u001b[39m=\u001b[39m load_yaml(args\u001b[39m.\u001b[39menv_config_path \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mvalid.yml\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     81\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_env_config \u001b[39m=\u001b[39m load_yaml(args\u001b[39m.\u001b[39menv_config_path \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtest.yml\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 82\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_env_instance \u001b[39m=\u001b[39m Tradingenv(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_env_config)\n\u001b[0;32m     83\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalid_env_instance \u001b[39m=\u001b[39m Tradingenv(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalid_env_config)\n\u001b[0;32m     84\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_env_instance \u001b[39m=\u001b[39m Tradingenv(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_env_config)\n",
      "File \u001b[1;32mc:\\Users\\zzyy\\Desktop\\TradeMaster\\competition\\..\\env\\PM\\portfolio_for_EIIE.py:80\u001b[0m, in \u001b[0;36mTradingenv.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[39m# initially, the self.state's shape is stock_dim*len(tech_indicator_list)\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([[\n\u001b[0;32m     77\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mtic \u001b[39m==\u001b[39m tic][tech]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m     78\u001b[0m     \u001b[39mfor\u001b[39;00m tech \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtech_indicator_list\n\u001b[0;32m     79\u001b[0m ] \u001b[39mfor\u001b[39;00m tic \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mtic\u001b[39m.\u001b[39munique()])\n\u001b[1;32m---> 80\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mtranspose(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstate, (\u001b[39m0\u001b[39;49m, \u001b[39m2\u001b[39;49m, \u001b[39m1\u001b[39;49m))\n\u001b[0;32m     81\u001b[0m \u001b[39m# self.state = np.transpose(self.state, (2, 0, 2))\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[39m# 此时返回的维度：(时间长度，tic数量，特征数量)\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[39m#TCN目前只能处理单个时间序列 所以我们的想法是把tic数量当作batch_size 以特征数量当作channel数进行处理 最后返回符合Kl*tic数*特征数\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[39m#deeptrader貌似并没有做fcl st tcn输入与输出的维度可以不同\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mterminal \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mtranspose\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\zzyy\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:660\u001b[0m, in \u001b[0;36mtranspose\u001b[1;34m(a, axes)\u001b[0m\n\u001b[0;32m    601\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_transpose_dispatcher)\n\u001b[0;32m    602\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtranspose\u001b[39m(a, axes\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    603\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    604\u001b[0m \u001b[39m    Reverse or permute the axes of an array; returns the modified array.\u001b[39;00m\n\u001b[0;32m    605\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    658\u001b[0m \n\u001b[0;32m    659\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 660\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39mtranspose\u001b[39;49m\u001b[39m'\u001b[39;49m, axes)\n",
      "File \u001b[1;32mc:\\Users\\zzyy\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "\u001b[1;31mValueError\u001b[0m: axes don't match array"
     ]
    }
   ],
   "source": [
    "args = parser.parse_args(args=[])\n",
    "agent=trader(args)\n",
    "# agent.train_with_valid()\n",
    "\n",
    "print(agent.train_env_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing & Generate Submission Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_information_1=pd.read_csv(\"data/test_input_1.csv\",index_col=0)\n",
    "# test_information_2=pd.read_csv(\"data/test_input_2.csv\",index_col=0)\n",
    "# technical_indicator=[\"feature_0\",\"feature_1\",\"feature_2\",\"feature_3\",\"feature_4\",\"feature_5\",\"feature_6\",\"feature_7\",\"feature_8\",\"feature_9\",\"feature_10\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# action_list_1=[]\n",
    "# for date in test_information_1.index.unique():\n",
    "#     s=test_information_1[test_information_1.index==date][technical_indicator].values\n",
    "#     shape=s.shape\n",
    "#     s=s.reshape(shape[0],1,shape[1])\n",
    "#     s=torch.from_numpy(s).float()\n",
    "#     action=agent.net(s)\n",
    "#     #here the origional action for the environment consider the cash, which is more pracitical in real world, but for \n",
    "#     #the competition, we only need the last 15 weights for the assets, therefore we need to normalize the result as well\n",
    "#     action=action.detach().float().numpy()\n",
    "#     action=action[1:]/np.sum(action[1:])\n",
    "#     action_list_1.append(action)\n",
    "# action_list_1=np.array(action_list_1)\n",
    "# action_list_1=action_list_1.astype(float)\n",
    "# np.save(\"result/EIIE/action/action1.npy\",action_list_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# action_list_2=[]\n",
    "# for date in test_information_2.index.unique():\n",
    "#     s=test_information_2[test_information_2.index==date][technical_indicator].values\n",
    "#     shape=s.shape\n",
    "#     s=s.reshape(shape[0],1,shape[1])\n",
    "#     s=torch.from_numpy(s).float()\n",
    "#     action=agent.net(s)\n",
    "#     #here the origional action for the environment consider the cash, which is more pracitical in real world, but for \n",
    "#     #the competition, we only need the last 15 weights for the assets, therefore we need to normalize the result as well\n",
    "#     action=action.detach().float().numpy()\n",
    "#     action=action[1:]/np.sum(action[1:])\n",
    "#     action_list_2.append(action)\n",
    "# action_list_2=np.array(action_list_2)\n",
    "# action_list_2=action_list_2.astype(float)\n",
    "# np.save(\"result/EIIE/action/action2.npy\",action_list_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, Compress the 2 file as a zip file as submission file.\n",
    "Please notice that the zip file should only contain this 2 files name after `action1.npy` and `action2.npy` with no external folder. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next is core code of the agent.\n",
    "## RL Environment Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In TradeMaster, you need to provide 3 RL environment configuration before building an agent. The TradeMaster agents will automatically follow the process using the training RL environment to train the agent, test it in the validation environment and pick the best model of training and pose it in the testing environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_env_instance=agent.train_env_instance\n",
    "valid_env_instance=agent.valid_env_instance\n",
    "test_env_instance=agent.train_env_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reseting the environment, means to clear all the history and start from the begining. \n",
    "# It will return the initial state  \n",
    "# Here is an example of posing the random action to the train_env_instance\n",
    "# s=train_env_instance.reset()\n",
    "# action=np.random.rand(16)\n",
    "# done=False\n",
    "# while not done:\n",
    "#     old_state = s\n",
    "#     s, reward, done, _ =train_env_instance.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_action_score(action_score_list):\n",
    "    true_action_list = []\n",
    "    for action_score in action_score_list:\n",
    "        if np.sum(action_score) == 1:\n",
    "            action = action_score\n",
    "        else:\n",
    "            action = np.exp(action_score) / np.sum(np.exp(action_score))\n",
    "        true_action_list.append(action)\n",
    "    return np.array(true_action_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next is the core code of EIIE, I will decompose it so that you can understand the process of training, making it easier for you to build your own agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the net\n",
    "# Just like the supervised leanrning process, we need a net to regress something, here the EIIE is Actor-Critic RL model where we need a actor to to generate policy and a critic\\\n",
    "# to judge whether the state is good or not\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class EIIE_con(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, length, kernel_size=1):\n",
    "        super(EIIE_con, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.length = length\n",
    "        self.act = torch.nn.ReLU(inplace=False)\n",
    "        self.con1d = nn.Conv1d(self.in_channels,\n",
    "                               self.out_channels,\n",
    "                               kernel_size=1)\n",
    "        self.con2d = nn.Conv1d(self.out_channels,\n",
    "                               1,\n",
    "                               kernel_size=1)\n",
    "        self.con3d = nn.Conv1d(1, 1, kernel_size=1)\n",
    "        self.para = torch.nn.Parameter(torch.ones(1).requires_grad_())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.con1d(x)\n",
    "        x = self.act(x)\n",
    "        x = self.con2d(x)\n",
    "        x = self.act(x)\n",
    "        x = self.con3d(x)\n",
    "        x = x.view(-1)\n",
    "\n",
    "        # self.linear2 = nn.Linear(len(x), len(x) + 1)\n",
    "        # x = self.linear2(x)\n",
    "        x = torch.cat((x, self.para), dim=0)\n",
    "        x = torch.softmax(x, dim=0)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class EIIE_lstm(nn.Module):\n",
    "    def __init__(self, n_features, layer_num, n_hidden):\n",
    "        super(EIIE_lstm, self).__init__()\n",
    "        self.n_features = n_features\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_layers = layer_num\n",
    "        self.lstm = nn.LSTM(input_size=n_features,\n",
    "                            hidden_size=self.n_hidden,\n",
    "                            num_layers=self.n_layers,\n",
    "                            batch_first=True)\n",
    "        self.linear = nn.Linear(self.n_hidden, 1)\n",
    "        self.con3d = nn.Conv1d(1, 1, kernel_size=1)\n",
    "        self.para = torch.nn.Parameter(torch.ones(1).requires_grad_())\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        # print('1',lstm_out[:, -1, :].shape)\n",
    "        # print('2',lstm_out[:, :, :].shape)\n",
    "        # x = self.linear(lstm_out).transpose(1, 2)\n",
    "        x = self.linear(lstm_out[:, -1, :]).view(-1, 1, 1)\n",
    "        # print('3',x.transpose(1, 2).shape)        \n",
    "        # print('4',x.shape)\n",
    "        # print('5',x)\n",
    "        x = self.con3d(x)\n",
    "        # print('6',x.shape)\n",
    "        x = x.view(-1)\n",
    "        # print('7',x.shape)\n",
    "        x = torch.cat((x, self.para), dim=0)\n",
    "        x = torch.softmax(x, dim=0)\n",
    "        # print(x.shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EIIE_rnn(nn.Module):\n",
    "    def __init__(self, n_features, layer_num, n_hidden):\n",
    "        super(EIIE_rnn, self).__init__()\n",
    "        self.n_features = n_features\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_layers = layer_num\n",
    "        self.rnn = nn.RNN(input_size=n_features,\n",
    "                          hidden_size=self.n_hidden,\n",
    "                          num_layers=self.n_layers,\n",
    "                          batch_first=True)\n",
    "        self.linear = nn.Linear(self.n_hidden, 1)\n",
    "        self.con3d = nn.Conv1d(1, 1, kernel_size=1)\n",
    "        self.para = torch.nn.Parameter(torch.ones(1).requires_grad_())\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.rnn(x)\n",
    "        x = self.linear(lstm_out[:, -1, :]).view(-1, 1, 1)\n",
    "        x = self.con3d(x)\n",
    "        x = x.view(-1)\n",
    "        x = torch.cat((x, self.para), dim=0)\n",
    "        x = torch.softmax(x, dim=0)\n",
    "        return x\n",
    "    \n",
    "class EIIE_critirc(nn.Module):\n",
    "    def __init__(self, n_features, layer_num, n_hidden):\n",
    "        super(EIIE_critirc, self).__init__()\n",
    "        self.n_features = n_features\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_layers = layer_num\n",
    "        self.lstm = nn.LSTM(input_size=n_features,\n",
    "                            hidden_size=self.n_hidden,\n",
    "                            num_layers=self.n_layers,\n",
    "                            batch_first=True)\n",
    "        self.linear = nn.Linear(self.n_hidden, 1)\n",
    "        self.con3d = nn.Conv1d(1, 1, kernel_size=1)\n",
    "        self.para = torch.nn.Parameter(torch.ones(1).requires_grad_())\n",
    "\n",
    "    def forward(self, x, a):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        x = self.linear(lstm_out[:, -1, :]).view(-1, 1, 1)\n",
    "        x = self.con3d(x)\n",
    "        x = x.view(-1)\n",
    "        x = torch.cat((x, self.para, a), dim=0)\n",
    "        x = torch.nn.ReLU(inplace=False)(x)\n",
    "        number_nodes = len(x)\n",
    "        self.linear2 = nn.Linear(number_nodes, 1)\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here are the code for the trader, the key lies on the learn function\n",
    "model_name = \"lstm_win3_noStandardized_2layer_16hidden_0.99g_recent1000\"\n",
    "result_folder_location = \"result/\"+ model_name + \"/test_result/\"\n",
    "model_folder_location = \"result/\"+ model_name + \"/trained_model\"\n",
    "class trader:\n",
    "    def __init__(self):\n",
    "        self.num_epoch = 10\n",
    "        self.GPU_IN_USE = torch.cuda.is_available()\n",
    "        self.device = torch.device('cpu' if self.GPU_IN_USE else 'cpu')\n",
    "        self.model_path = model_folder_location\n",
    "        if not os.path.exists(self.model_path):\n",
    "            os.makedirs(self.model_path)\n",
    "        self.result_path = result_folder_location\n",
    "        if not os.path.exists(self.result_path):\n",
    "            os.makedirs(self.result_path)\n",
    "        self.train_env_instance = train_env_instance\n",
    "        self.valid_env_instance = valid_env_instance\n",
    "        self.test_env_instance = test_env_instance\n",
    "        self.n_hidden = 16\n",
    "        self.input_channel = 11\n",
    "        self.layer_num = 2\n",
    "        self.net = EIIE_lstm(self.input_channel, self.layer_num,\n",
    "                           self.n_hidden)\n",
    "        \n",
    "        self.critic = EIIE_critirc(self.input_channel, self.layer_num,\n",
    "                                  self.n_hidden)\n",
    "        self.test_action_memory = []  # to store the\n",
    "        self.optimizer_actor = torch.optim.Adam(self.net.parameters(), lr=1e-4)\n",
    "        self.optimizer_critic = torch.optim.Adam(self.critic.parameters(),\n",
    "                                                 lr=1e-4)\n",
    "        self.memory_counter = 0\n",
    "        self.memory_capacity = 1000\n",
    "        self.s_memory = []\n",
    "        self.a_memory = []\n",
    "        self.r_memory = []\n",
    "        self.sn_memory = []\n",
    "        self.policy_update_frequency = 500\n",
    "        self.critic_learn_time = 0\n",
    "        self.gamma = 0.99\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self.net = self.net.to(self.device)\n",
    "        self.critic = self.critic.to(self.device)\n",
    "\n",
    "    def store_transition(\n",
    "        self,\n",
    "        s,\n",
    "        a,\n",
    "        r,\n",
    "        s_,\n",
    "    ):  # 定义记忆存储函数 (这里输入为一个transition)\n",
    "\n",
    "        self.memory_counter = self.memory_counter + 1\n",
    "        if self.memory_counter < self.memory_capacity:\n",
    "            self.s_memory.append(s)\n",
    "            self.a_memory.append(a)\n",
    "            self.r_memory.append(r)\n",
    "            self.sn_memory.append(s_)\n",
    "        else:\n",
    "            number = self.memory_counter % self.memory_capacity\n",
    "            self.s_memory[number - 1] = s\n",
    "            self.a_memory[number - 1] = a\n",
    "            self.r_memory[number - 1] = r\n",
    "            self.sn_memory[number - 1] = s_\n",
    "\n",
    "    def compute_single_action(self, state):\n",
    "        state = torch.from_numpy(state).float().to(self.device)\n",
    "        action = self.net(state)\n",
    "        action = action.detach().cpu().numpy()\n",
    "        return action\n",
    "\n",
    "    def learn(self):\n",
    "        # here is the core of the trader, it shows how the updates coming out\n",
    "        # we first need to have some stored the transcation(s,a,r,s_) \n",
    "        length = len(self.s_memory)\n",
    "        out1 = random.sample(range(length), int(length / 10))\n",
    "        # random sample\n",
    "        s_learn = []\n",
    "        a_learn = []\n",
    "        r_learn = []\n",
    "        sn_learn = []\n",
    "        for number in out1:\n",
    "            s_learn.append(self.s_memory[number])\n",
    "            a_learn.append(self.a_memory[number])\n",
    "            r_learn.append(self.r_memory[number])\n",
    "            sn_learn.append(self.sn_memory[number])\n",
    "        self.critic_learn_time = self.critic_learn_time + 1\n",
    "        # for the transcation we have stored, we need to update the actor and critic\n",
    "        # for the actor, we need to comput the action and use the critic to judge the action\n",
    "        # we need to update the actor so that for every action it choose, it can gain more scores from a critic than other action \n",
    "        # for the critic , we simply use the td_error to update it because it is MDP\n",
    "\n",
    "        for bs, ba, br, bs_ in zip(s_learn, a_learn, r_learn, sn_learn):\n",
    "            #update actor\n",
    "            a = self.net(bs)\n",
    "            q = self.critic(bs, a)\n",
    "            a_loss = -torch.mean(q)\n",
    "            self.optimizer_actor.zero_grad()\n",
    "            a_loss.backward(retain_graph=True)\n",
    "            self.optimizer_actor.step()\n",
    "            #update critic\n",
    "            a_ = self.net(bs_)\n",
    "            q_ = self.critic(bs_, a_.detach())\n",
    "            q_target = br + self.gamma * q_\n",
    "            q_eval = self.critic(bs, ba.detach())\n",
    "            # print(q_eval)\n",
    "            # print(q_target)\n",
    "            td_error = self.mse_loss(q_target.detach(), q_eval)\n",
    "            # print(td_error)\n",
    "            self.optimizer_critic.zero_grad()\n",
    "            td_error.backward()\n",
    "            self.optimizer_critic.step()\n",
    "\n",
    "    def train_with_valid(self):\n",
    "        # print(self.train_env_instance.length_day)\n",
    "        rewards_list = []\n",
    "        for i in range(self.num_epoch):\n",
    "            j = 0\n",
    "            done = False\n",
    "            s = self.train_env_instance.reset()\n",
    "            while not done:\n",
    "\n",
    "                old_state = s\n",
    "                # print('checking input size: ', torch.from_numpy(s).float().size())\n",
    "                action = self.net(torch.from_numpy(s).float())\n",
    "                s, reward, done, _ = self.train_env_instance.step(\n",
    "                    action.detach().numpy())\n",
    "                self.store_transition(\n",
    "                    torch.from_numpy(old_state).float().to(self.device),\n",
    "                    action,\n",
    "                    torch.tensor(reward).float().to(self.device),\n",
    "                    torch.from_numpy(s).float().to(self.device))\n",
    "                j = j + 1\n",
    "                if j % 200 == 1:\n",
    "\n",
    "                    self.learn()\n",
    "            all_model_path = self.model_path + \"/all_model/\"\n",
    "            best_model_path = self.model_path + \"/best_model/\"\n",
    "            if not os.path.exists(all_model_path):\n",
    "                os.makedirs(all_model_path)\n",
    "            if not os.path.exists(best_model_path):\n",
    "                os.makedirs(best_model_path)\n",
    "            torch.save(self.net,\n",
    "                       all_model_path + \"actor_num_epoch_{}.pth\".format(i))\n",
    "            torch.save(self.critic,\n",
    "                       all_model_path + \"critic_num_epoch_{}.pth\".format(i))\n",
    "            s = self.valid_env_instance.reset()\n",
    "            done = False\n",
    "            rewards = 0\n",
    "            while not done:\n",
    "\n",
    "                old_state = s\n",
    "                action = self.net(torch.from_numpy(s).float())\n",
    "                s, reward, done, _ = self.valid_env_instance.step(\n",
    "                    action.detach().numpy())\n",
    "                rewards = rewards + reward\n",
    "            rewards_list.append(rewards)\n",
    "        index = rewards_list.index(np.max(rewards_list))\n",
    "        actor_model_path = all_model_path + \"actor_num_epoch_{}.pth\".format(\n",
    "            index)\n",
    "        critic_model_path = all_model_path + \"critic_num_epoch_{}.pth\".format(\n",
    "            index)\n",
    "        self.net = torch.load(actor_model_path)\n",
    "        self.critic = torch.load(critic_model_path)\n",
    "        torch.save(self.net, best_model_path + \"actor.pth\")\n",
    "        torch.save(self.critic, best_model_path + \"critic.pth\")\n",
    "\n",
    "    def test(self):\n",
    "        s = self.test_env_instance.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            old_state = s\n",
    "            action = self.net(torch.from_numpy(s).float())\n",
    "            s, reward, done, _ = self.test_env_instance.step(\n",
    "                action.detach().numpy())\n",
    "        df_return = self.test_env_instance.save_portfolio_return_memory()\n",
    "        df_assets = self.test_env_instance.save_asset_memory()\n",
    "        assets = df_assets[\"total assets\"].values\n",
    "        daily_return = df_return.daily_return.values\n",
    "        df = pd.DataFrame()\n",
    "        df[\"daily_return\"] = daily_return\n",
    "        df[\"total assets\"] = assets\n",
    "        if not os.path.exists(self.result_path):\n",
    "            os.makedirs(self.result_path)\n",
    "        df.to_csv(self.result_path + \"/result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'args'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\zzyy\\Desktop\\TradeMaster\\competition\\competition copy.ipynb Cell 32\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/zzyy/Desktop/TradeMaster/competition/competition%20copy.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m agent\u001b[39m=\u001b[39mtrader()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zzyy/Desktop/TradeMaster/competition/competition%20copy.ipynb#X43sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m agent\u001b[39m.\u001b[39mtrain_with_valid()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/zzyy/Desktop/TradeMaster/competition/competition%20copy.ipynb#X43sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m test_information_1\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mdata/test_input_1.csv\u001b[39m\u001b[39m\"\u001b[39m,index_col\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'args'"
     ]
    }
   ],
   "source": [
    "agent=trader()\n",
    "agent.train_with_valid()\n",
    "test_information_1=pd.read_csv(\"data/test_input_1.csv\",index_col=0)\n",
    "test_information_2=pd.read_csv(\"data/test_input_2.csv\",index_col=0)\n",
    "technical_indicator=[\"feature_0\",\"feature_1\",\"feature_2\",\"feature_3\",\"feature_4\",\"feature_5\",\"feature_6\",\"feature_7\",\"feature_8\",\"feature_9\",\"feature_10\"]\n",
    "action_list_1=[]\n",
    "for date in test_information_1.index.unique():\n",
    "    s=test_information_1[test_information_1.index==date][technical_indicator].values\n",
    "    shape=s.shape\n",
    "    s=s.reshape(shape[0],1,shape[1])\n",
    "    s=torch.from_numpy(s).float()\n",
    "    action=agent.net(s)\n",
    "    #here the origional action for the environment consider the cash, which is more pracitical in real world, but for \n",
    "    #the competition, we only need the last 15 weights for the assets, therefore we need to normalize the result as well\n",
    "    action=action.detach().float().numpy()\n",
    "    action=action[1:]/np.sum(action[1:])\n",
    "    action_list_1.append(action)\n",
    "action_list_1=np.array(action_list_1)\n",
    "action_list_1=action_list_1.astype(float)\n",
    "# action_list_1 = check_action_score(action_list_1)\n",
    "np.save(result_folder_location + \"action1.npy\",action_list_1)\n",
    "action_list_2=[]\n",
    "for date in test_information_2.index.unique():\n",
    "    s=test_information_2[test_information_2.index==date][technical_indicator].values\n",
    "    shape=s.shape\n",
    "    s=s.reshape(shape[0],1,shape[1])\n",
    "    s=torch.from_numpy(s).float()\n",
    "    action=agent.net(s)\n",
    "    #here the origional action for the environment consider the cash, which is more pracitical in real world, but for \n",
    "    #the competition, we only need the last 15 weights for the assets, therefore we need to normalize the result as well\n",
    "    action=action.detach().float().numpy()\n",
    "    action=action[1:]/np.sum(action[1:])\n",
    "    action_list_2.append(action)\n",
    "action_list_2=np.array(action_list_2)\n",
    "action_list_2=action_list_2.astype(float)\n",
    "# action_list_2 = check_action_score(action_list_2)\n",
    "np.save(result_folder_location + \"action2.npy\",action_list_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, Compress the 2 file as a zip file as submission file."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>tic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>0.005902</td>\n",
       "      <td>0.007303</td>\n",
       "      <td>-0.011205</td>\n",
       "      <td>-0.080377</td>\n",
       "      <td>0.014513</td>\n",
       "      <td>-0.014406</td>\n",
       "      <td>0.022389</td>\n",
       "      <td>0.040416</td>\n",
       "      <td>0.055082</td>\n",
       "      <td>0.076751</td>\n",
       "      <td>0.092754</td>\n",
       "      <td>1011</td>\n",
       "      <td>24.990000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>-0.015651</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>-0.025665</td>\n",
       "      <td>-0.163744</td>\n",
       "      <td>0.020990</td>\n",
       "      <td>0.006552</td>\n",
       "      <td>0.038172</td>\n",
       "      <td>0.050043</td>\n",
       "      <td>0.054639</td>\n",
       "      <td>0.053370</td>\n",
       "      <td>0.054584</td>\n",
       "      <td>1011</td>\n",
       "      <td>150.789993</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>0.006211</td>\n",
       "      <td>0.007764</td>\n",
       "      <td>-0.012422</td>\n",
       "      <td>-0.090157</td>\n",
       "      <td>0.005464</td>\n",
       "      <td>-0.005155</td>\n",
       "      <td>0.029875</td>\n",
       "      <td>0.044375</td>\n",
       "      <td>0.051618</td>\n",
       "      <td>0.057336</td>\n",
       "      <td>0.064864</td>\n",
       "      <td>1011</td>\n",
       "      <td>64.400002</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>-0.002577</td>\n",
       "      <td>0.001895</td>\n",
       "      <td>-0.017283</td>\n",
       "      <td>-0.103166</td>\n",
       "      <td>0.013133</td>\n",
       "      <td>0.006610</td>\n",
       "      <td>0.049030</td>\n",
       "      <td>0.060890</td>\n",
       "      <td>0.069614</td>\n",
       "      <td>0.076646</td>\n",
       "      <td>0.082724</td>\n",
       "      <td>1011</td>\n",
       "      <td>131.919998</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>0.013636</td>\n",
       "      <td>0.014610</td>\n",
       "      <td>-0.019643</td>\n",
       "      <td>-0.164934</td>\n",
       "      <td>0.002115</td>\n",
       "      <td>0.027662</td>\n",
       "      <td>0.067581</td>\n",
       "      <td>0.081310</td>\n",
       "      <td>0.079326</td>\n",
       "      <td>0.079448</td>\n",
       "      <td>0.091564</td>\n",
       "      <td>1011</td>\n",
       "      <td>61.599998</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>-0.005861</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>-0.008884</td>\n",
       "      <td>-0.048781</td>\n",
       "      <td>0.004924</td>\n",
       "      <td>0.004808</td>\n",
       "      <td>0.004437</td>\n",
       "      <td>-0.003865</td>\n",
       "      <td>-0.007787</td>\n",
       "      <td>-0.005974</td>\n",
       "      <td>-0.001445</td>\n",
       "      <td>2010</td>\n",
       "      <td>218.380005</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>-0.003051</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>-0.008701</td>\n",
       "      <td>-0.044475</td>\n",
       "      <td>0.003288</td>\n",
       "      <td>-0.002158</td>\n",
       "      <td>-0.003520</td>\n",
       "      <td>-0.003921</td>\n",
       "      <td>-0.007257</td>\n",
       "      <td>-0.005281</td>\n",
       "      <td>-0.003373</td>\n",
       "      <td>2010</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>-0.011265</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>-0.012235</td>\n",
       "      <td>-0.106114</td>\n",
       "      <td>0.009261</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.004432</td>\n",
       "      <td>0.003516</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>2010</td>\n",
       "      <td>128.145309</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>-0.003843</td>\n",
       "      <td>0.001337</td>\n",
       "      <td>-0.008187</td>\n",
       "      <td>-0.056113</td>\n",
       "      <td>0.003858</td>\n",
       "      <td>-0.001571</td>\n",
       "      <td>-0.015221</td>\n",
       "      <td>-0.024127</td>\n",
       "      <td>-0.032916</td>\n",
       "      <td>-0.031225</td>\n",
       "      <td>-0.030989</td>\n",
       "      <td>2010</td>\n",
       "      <td>59.849998</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>-0.005279</td>\n",
       "      <td>0.000960</td>\n",
       "      <td>-0.007472</td>\n",
       "      <td>-0.056455</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>-0.000919</td>\n",
       "      <td>-0.003716</td>\n",
       "      <td>-0.013386</td>\n",
       "      <td>-0.021135</td>\n",
       "      <td>-0.028535</td>\n",
       "      <td>-0.036103</td>\n",
       "      <td>2010</td>\n",
       "      <td>145.869995</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "1011   0.005902   0.007303  -0.011205  -0.080377   0.014513  -0.014406   \n",
       "1011  -0.015651   0.002984  -0.025665  -0.163744   0.020990   0.006552   \n",
       "1011   0.006211   0.007764  -0.012422  -0.090157   0.005464  -0.005155   \n",
       "1011  -0.002577   0.001895  -0.017283  -0.103166   0.013133   0.006610   \n",
       "1011   0.013636   0.014610  -0.019643  -0.164934   0.002115   0.027662   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "2010  -0.005861   0.000595  -0.008884  -0.048781   0.004924   0.004808   \n",
       "2010  -0.003051   0.000452  -0.008701  -0.044475   0.003288  -0.002158   \n",
       "2010  -0.011265   0.000597  -0.012235  -0.106114   0.009261   0.002701   \n",
       "2010  -0.003843   0.001337  -0.008187  -0.056113   0.003858  -0.001571   \n",
       "2010  -0.005279   0.000960  -0.007472  -0.056455   0.003923  -0.000919   \n",
       "\n",
       "      feature_6  feature_7  feature_8  feature_9  feature_10  date  \\\n",
       "1011   0.022389   0.040416   0.055082   0.076751    0.092754  1011   \n",
       "1011   0.038172   0.050043   0.054639   0.053370    0.054584  1011   \n",
       "1011   0.029875   0.044375   0.051618   0.057336    0.064864  1011   \n",
       "1011   0.049030   0.060890   0.069614   0.076646    0.082724  1011   \n",
       "1011   0.067581   0.081310   0.079326   0.079448    0.091564  1011   \n",
       "...         ...        ...        ...        ...         ...   ...   \n",
       "2010   0.004437  -0.003865  -0.007787  -0.005974   -0.001445  2010   \n",
       "2010  -0.003520  -0.003921  -0.007257  -0.005281   -0.003373  2010   \n",
       "2010   0.004432   0.003516   0.000011   0.000603    0.000505  2010   \n",
       "2010  -0.015221  -0.024127  -0.032916  -0.031225   -0.030989  2010   \n",
       "2010  -0.003716  -0.013386  -0.021135  -0.028535   -0.036103  2010   \n",
       "\n",
       "           close  tic  \n",
       "1011   24.990000    0  \n",
       "1011  150.789993    1  \n",
       "1011   64.400002    2  \n",
       "1011  131.919998    3  \n",
       "1011   61.599998    4  \n",
       "...          ...  ...  \n",
       "2010  218.380005   10  \n",
       "2010  177.000000   11  \n",
       "2010  128.145309   12  \n",
       "2010   59.849998   13  \n",
       "2010  145.869995   14  \n",
       "\n",
       "[15000 rows x 14 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/train.csv', index_col=0)\n",
    "df1 = pd.read_csv('data/train.csv', index_col=0).tail(15000)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0ef60ae2acd7272b700e0d59c8441536db607a994a33d88fe9cbde0933029ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
